# Dublin Buses Delay Prediction 
 Final Project of the Data Mangment and Gathering Lab 094290
 Ben Filiarsky & Itzik Koyfman
<p align='center'>
<img src=https://user-images.githubusercontent.com/74211354/105638890-fb00f900-5e7d-11eb-9042-6d9230babc37.jpg width=75% height=400px alt='Dublin Buses'></img>
</p>

## Overview


## Technologies

* Processing framework - Apache Sparkâ„¢.
<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/1200px-Apache_Spark_logo.svg.png width=5% height=5% align='center' style="padding-bottom:6px" alt='Docker'></img>
* Data warehouse - Elasticsearch cluster.
<img src=https://www.elastic.co/static-res/images/elastic-logo-200.png width=4% height=4% align='center' padding-left=2% alt='Docker'></img>
* Docker - running Elasticsearch and Kibana on Ubuntu VMs.
<img src=https://pbs.twimg.com/profile_images/1273307847103635465/lfVWBmiW_400x400.png width=5% height=5% align='center' padding-left=2% alt='Docker'></img>

## Requirments

### Web App
* The app currently does not have a public domain.
* In order to run the app, Pyhton 3.7+ is required, please install the neccesary packages using 

    ```pip install -r requirement.txt```
* Run the app using ```python app.py```

### Processing Framework
* Processing is executed in the Databricks enviroment and requires Spark 2.4.5 (Pyspark).
* Run docker on your VM using the code and the configuration file (docker-compose.yml).

    ```sudo /opt/anaconda3/bin/docker-compose up -d```

## Usage

### Delay predictions assesmnet

### Route planning

### Uploading Data
